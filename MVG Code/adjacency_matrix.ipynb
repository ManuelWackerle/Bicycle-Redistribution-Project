{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes the code builds a matrix between the hexagonal cells (or any array of coordinate pairs). The input is the output of the data preprocessing notebook (I think in your repository the file \"felix_data.csv\"). However, it will be easy to modify the code slighty in order to calculate distances between other coordinates if that would be needed in the future.\n",
    "For information on the routing, see http://project-osrm.org/docs/v5.24.0/api/#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need the file.\n",
    "df = pd.read_csv(\"test_out.csv\") # insert correct path and name here. should be the output of the other notebook.\n",
    "df.columns = ['nr', 'id', 'delta', 'x_coord', 'y_coord'] # can be modified/deleted if another input is used\n",
    "# some sanity checks (coords far away from Munich will be dropped)\n",
    "df = df[(47.5<df.x_coord) & (df.x_coord<48.5) & (11<df.y_coord) & (df.y_coord<12)]\n",
    "# build a dictionary with coordinates as tuple and id as key; first build a row with coords as a tuple\n",
    "df['lat_lon_tuple'] = list(zip(df.y_coord,df.x_coord))\n",
    "coords = pd.Series(df.lat_lon_tuple.values,index=df.id).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a query can't contain 743*743 coordinate tuples. we therefore have to slice it into chunks, which we will later on reassemble.\n",
    "# as we always combine to \"packs\" (origins and destinations), the list for the query will contain 2*max_size coordinate tuples.\n",
    "# queries containing 100 tuples have shown to run stable.\n",
    "max_size = 50\n",
    "coord_packs = []\n",
    "for i in range (0, len(coords)//max_size+1,1):\n",
    "    slice_start = i*max_size\n",
    "    slice_end = slice_start + max_size\n",
    "    coord_packs.append(dict(itertools.islice(coords.items(), slice_start, slice_end)))\n",
    "#coord_packs.append(dict(itertools.islice(coords.items(), (len(coords)-len(coords)%max_size), len(coords)))) # used in a former version to add the last, shorter bunch\n",
    "#coord_packs = coord_packs[13:] # use this for debugging to limit the size of the matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a query has the following form:\n",
    "# /table/v1/{profile}/{coordinates}?{sources}=[{elem}...];&{destinations}=[{elem}...]&annotations={duration|distance|duration,distance}\n",
    "# in this cell, we procuce the {sources} and {destinations}, telling OSRM how to interpret the list of coordinates\n",
    "\n",
    "def create_mapping(origin_len, dest_len):\n",
    "    sources = \"\"\n",
    "    destinations = \"\"\n",
    "    for i in range (0, dest_len, 1):\n",
    "        destinations = destinations + (str(i+origin_len)+';')\n",
    "    for i in range (0, origin_len, 1):\n",
    "        sources = sources + (str(i)+';')\n",
    "    sources = sources[:-1]\n",
    "    destinations = destinations[:-1]\n",
    "    return sources, destinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we query the sub-matrices and assemble them to a big one. On my machine (FYI: i710850H 2,7 GHz 16GB RAM) this takes  ~23 min.\n",
    "res = pd.DataFrame()\n",
    "for col, base_coords in enumerate(coord_packs):\n",
    "    res_col_tmp = pd.DataFrame()\n",
    "    for row, target_coords in enumerate(coord_packs):\n",
    "        print(f\"col: {col}\\t\\trow: {row}\") # can be disabled if annoying (get's pretty long)\n",
    "        # make a string from coordinate tuples\n",
    "        coords_origin = \"\".join([str(val[0])+','+str(val[1])+';' for val in list(base_coords.values())])\n",
    "        coords_destination = \"\".join([str(val[0])+','+str(val[1])+';' for val in list(target_coords.values())])\n",
    "        # add origins and destinations, delete the last ';'\n",
    "        coords_str = (coords_origin+coords_destination)[:-1]\n",
    "        sources, destinations = create_mapping(len(base_coords), len(target_coords))\n",
    "        req_str=f\"http://router.project-osrm.org/table/v1/driving/{coords_str}?sources={sources}&destinations={destinations}&annotations=distance\"\n",
    "        # get the request\n",
    "        r = requests.get(req_str)\n",
    "        # load the response as a json and retrieve the relevant information. Unit: meters\n",
    "        durs_tmp = json.loads(r.content).get(\"distances\")\n",
    "        # load list of lists into DF\n",
    "        res_row_tmp = pd.DataFrame(durs_tmp, index=list(base_coords.keys()), columns=list(target_coords.keys()))\n",
    "        # assemble the column in the temporary DF\n",
    "        res_col_tmp = pd.concat([res_col_tmp, res_row_tmp],axis=1)#res.append(res_tmp)\n",
    "        # clean the variables just to be sure\n",
    "        coords_str, coords_origin, coords_destination = \"\", \"\", \"\"\n",
    "    # add the complete column to the results DF\n",
    "    res = pd.concat([res, res_col_tmp], axis=0)#res.append(res_tmp)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file as pickle and csv\n",
    "res.to_pickle(\"adjacency_matrix.pkl\")\n",
    "res.to_csv(\"adjacency_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is another version based on iterating over each cell - you will notice its too slow (even for my standards ;)\n",
    "# we need a DataFrame to store the results in\n",
    "res = pd.DataFrame()\n",
    "# now we iterate over the coordinates. \n",
    "count = 0 # counter for storing\n",
    "for base_id, base_coord in coords.items():\n",
    "    # remove the current coordinate so we can check the ways to all others\n",
    "    tmp_coords = coords.copy()\n",
    "    del tmp_coords[base_id]\n",
    "    print(count)\n",
    "    tmp_adjacencies = []\n",
    "    # now for each coord, we need to find the way to all other coords\n",
    "    for target_id, target_coord in tmp_coords.items():\n",
    "        count += 1\n",
    "        # get the route from OSMR: http://project-osrm.org/docs/v5.7.0/api/?language=Python#general-options\n",
    "        r = requests.get(f\"http://router.project-osrm.org/route/v1/driving/{base_coord[1]},{base_coord[0]};{target_coord[1]},{target_coord[0]}?overview=false&steps=false&overview=false\")\n",
    "        # uncomment the following lines for debugging or if interested\n",
    "        #dist = json.loads(r.content).get(\"routes\")[0].get('distance')\n",
    "        #print(json.loads(r.content))\n",
    "        #print(f\" start: {base_coord}, end: {target_coord}, dist: {dist}\")\n",
    "        res.loc[base_id, target_id] = json.loads(r.content).get(\"routes\")[0].get('distance')\n",
    "        # this takes long, so we should store from time to time.\n",
    "        if count % 1000 == 0:\n",
    "            res.to_pickle(\"res_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ee01fd1d8812b36236e8ef1ac919ceb21ec921e0363761052181dca760e2314"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
